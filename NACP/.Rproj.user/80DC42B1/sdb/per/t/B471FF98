{
    "contents" : "require(zoo)\nrequire(fields)\nrequire(pspline)\n\n\n\n###############################################################################################\n#\n# extracthadcru\n#\n###############################################################################################\nextracthadcru <- function(x,maxlat,minlat,maxlon,minlon) {\n \tforextraction <- outer(seq(maxlat,minlat,by=-5), seq(minlon,maxlon,by=5), f <-function(x,y)(paste(x,\"_\",y, sep=\"\")))\n\textracteddataset <- x[,c(forextraction)]\n}\n###############################################################################################\n#\n# loadhadcru\n#\n###############################################################################################\nloadhadcru <- function() {\nsetwd(\"/Users/frank/Desktop/frank/metdatathings/cru5x5\")\n\n\nHadCRUT3v <- scan(file=\"hadcrut3v.dat\", sep=\"\",skip=0, na.strings=\"-1.000e+30\")\nHadCRUT3v.matrix <- matrix(HadCRUT3v, ncol=2592,byrow=TRUE)\nHadCRUT3v.ts <- ts(HadCRUT3v.matrix, start=c(1850,1), frequency=12)\n\ngridnames <- outer(seq(87.5,-87.5,by=-5), seq(-177.5,177.5,by=5), f <-function(x,y)(paste(x,\"_\",y, sep=\"\"))) \ngridnames <- as.vector(t(gridnames))  # can use to rename columns\ncolnames(HadCRUT3v.ts) <- gridnames\nreturn(HadCRUT3v.ts)\n}\n\n###############################################################################################\n#\n# davidtsplot\n#\n###############################################################################################\ndavidtsplot <-  function(x,lty=1,lwd=1,xlab=\"Year\",ncol=1, col=tim.colors(ncol(x)),plotlegend=TRUE,y.intersp=.8, x.intersp=.8,...) {\nts.plot(x,lty=lty,lwd=lwd,xlab=xlab,col=col,...)\nif(plotlegend) legend(locator(1),colnames(x),lty=lty,col=col,lwd=lwd,ncol=ncol, y.intersp = y.intersp, x.intersp= x.intersp)\n}\n###############################################################################################\n#\n# compile chronologies\n# reads in tabs data from multiple files and compiles all of the relevant sections\n###############################################################################################\n\ncompilechronologies<- function(datasetnames) {\n\ndatasetnames.tabs <- paste(datasetnames,\"_tabs\",sep=\"\")\n\nfor (i in 1:length(datasetnames.tabs)) {\n\tassign(datasetnames.tabs[i], importtabsfromARSTAN(datasetnames.tabs[i]))\n}\n\nchronologies.num <- NULL\nchronologies.seg <- NULL\nchronologies.age <- NULL\nchronologies.raw <- NULL\nchronologies.std <- NULL\nchronologies.res <- NULL\nchronologies.ars <- NULL\n\nrcs.num <- NULL\nrcs.rcs <- NULL\nrcs.sig <- NULL\nrcs.crv <- NULL\n\n\nfor (i in 1:length(datasetnames.tabs)) {\n\t\ttemp <- get(datasetnames.tabs[i])\n\t\t\n\t\tchronologies.num <- ts.union(chronologies.num,temp$chronologystuff[,1])\n\t\tchronologies.seg <- ts.union(chronologies.seg,temp$chronologystuff[,2])\n\t\tchronologies.age <- ts.union(chronologies.age,temp$chronologystuff[,3])\n\t\tchronologies.raw <- ts.union(chronologies.raw,temp$chronologystuff[,4])\n\t\tchronologies.std <- ts.union(chronologies.std,temp$chronologystuff[,5])\n\t\tchronologies.res <- ts.union(chronologies.res,temp$chronologystuff[,6])\n\t\tchronologies.ars <- ts.union(chronologies.ars,temp$chronologystuff[,7])\n\n\t\trcs.num <- ts.union(rcs.num,temp$RCSstuff[,1])\n\t\trcs.rcs <- ts.union(rcs.rcs,temp$RCSstuff[,2])\n\t\trcs.sig <- ts.union(rcs.sig,temp$RCSstuff[,3])\n\t\trcs.crv <- ts.union(rcs.crv,temp$RCSstuff[,4])\t\t\n\t}\n\ncolnames(chronologies.num) <- datasetnames\ncolnames(chronologies.seg) <- datasetnames\ncolnames(chronologies.age) <- datasetnames\ncolnames(chronologies.raw) <- datasetnames\ncolnames(chronologies.std) <- datasetnames\ncolnames(chronologies.res) <- datasetnames\ncolnames(chronologies.ars) <- datasetnames\n\nif (is.integer(ncol(rcs.num)))\n\t{\n\tcolnames(rcs.num) <- datasetnames\n\tcolnames(rcs.rcs) <- datasetnames\n\tcolnames(rcs.sig) <- datasetnames\n\tcolnames(rcs.crv) <- datasetnames\n}\n\noutputlist <- list(\nchronologies.num = chronologies.num, \nchronologies.seg = chronologies.seg,\nchronologies.age = chronologies.age,\nchronologies.raw = chronologies.raw,\nchronologies.std = chronologies.std,\nchronologies.res = chronologies.res,\nchronologies.ars = chronologies.ars,\nrcs.num = rcs.num,\nrcs.rcs = rcs.rcs,\nrcs.sig = rcs.sig,\nrcs.crv = rcs.crv\n)\n\nreturn (outputlist)\n}\n\n\n\n##########################################################################################\n#function importtabsfromARSTAN\n#\n#reads in arstan tabs files and makes a list for the chronology part and the RCS part\n##########################################################################################\nimporttabsfromARSTAN <- function(x) {\n\t\n\ttempimport <- scan(file=x,sep = \"\\t\", skip=1, na.strings=c(\"-9.9900\",\"-9.990\",\"-9.99\"))\n\ttempimportnames <- scan(file=x,sep = \"\\t\", skip=0, na.strings=\"-9.9900\",nlines=1, what=\"character\")\n\t\n\ttreeringdata <- matrix(tempimport,ncol=length(tempimportnames), byrow=TRUE)\n\tcolnames(treeringdata) <- tempimportnames\n\ttstreeringdata <- ts(treeringdata[,-1], start=treeringdata[1,1])\n\t\n\tif (length(tempimportnames)==13)\n\t{\n\tRCSstuff <- coredata(tstreeringdata[,8:12])\n\tRCSstuff <- ts(RCSstuff[,-1], start=RCSstuff[1,1])\n\tchronologystuff <- tstreeringdata[,1:7]\n\t}\n\t\n\telse {\n\tchronologystuff <- tstreeringdata\n\tRCSstuff <- NULL\n\t}\n\t\noutput <- list(chronologystuff=chronologystuff,RCSstuff=RCSstuff)\n\nreturn(output)\n}\n\n\n##########################################################################################\n#function writemts\n#\n# writes multipletimeseries to a file\n##########################################################################################\n\nwritemts <- function(mts,file=\"outfile\",sigdigits=4) {\n\ttemp <- cbind(index(mts),round(mts,sigdigits))\n\tifelse(is.null(ncol(mts)), (colnames(temp) <- c(\"Year\",substitute(mts))),(colnames(temp) <- c(\"Year\",colnames(mts))))\n\twrite.table(temp,file,quote=FALSE,row.names=FALSE,sep=\"\t\")\n}\n\n\n\n\n\n##########################################################################################\n#function monthlycorrelobservationoverlap\n#\n# efficient !\n##########################################################################################\n\nmonthlycorrelobservationoverlap <- function(x) {\n\tpresencematrix <- 0*(as.matrix(x))+1\n\tpresencematrix[is.na(presencematrix)] <- 0\n\toverlapmatrix <- t(presencematrix[,-1])%*%presencematrix[,1]\n\toverlapmatrix\n}\n\n\n\n##########################################################################################\n#function fancymonthlycorrels\n#\n#can use something like this to select what should be plotted\n#barplot(a$correlations[c(13:31)],names.arg=c(colnames(a$correlations)[c(13:31)]))\n#\n##########################################################################################\n\nfancymonthlycorrels <- function(treeringdata,monthlydata,startyear,endyear) {\ntemp<- ts.union(treeringdata,lag(monthlydata,-1),monthlydata)\ncolnames(temp) <- c(\"treeringdata\",paste(\"p\",colnames(monthlydata),sep=\"\"),colnames(monthlydata))\ntemp <- window(temp,startyear,endyear)\nseasons <- cbind(rowMeans(temp[,2:13]),rowMeans(temp[,7:9]),rowMeans(temp[,5:10]),rowMeans(temp[,16:18]),rowMeans(temp[,18:19]),rowMeans(temp[,17:22]),rowMeans(temp[,18:20]),rowMeans(temp[,19:21]),rowMeans(temp[,19:20]),rowMeans(temp[,20:21])) # finish to include seasonal means,etc\ncolnames(seasons) <- c(\"pYear\",\"pJJA\",\"pAMJJAS\",\"MAM\",\"MJ\", \"AMJJAS\",\"MJJ\",\"JJA\",\"JJ\",\"JA\")\nseasons <- ts(seasons,start=start(temp)[1])\ntemp2 <- ts.union(temp,seasons)\ncolnames(temp2) <- c(colnames(temp),colnames(seasons))\ncorrelations <- cor(temp2[,1],temp2[,2:ncol(temp2)],use=\"pairwise.complete.obs\")\nnvalues <- monthlycorrelobservationoverlap(temp2)\nprint(temp2)\nreturn(correlations)\n}\n\n\n##########################################################################################\n#function cambial.age.array\n##########################################################################################\ncambial.age.array <- function(treeringdata, pith.offset=0) {\n\nif (length(pith.offset)==1) pith.offset <- rep(pith.offset,ncol(treeringdata))\nstopifnot (length(pith.offset)== ncol(treeringdata))\n\n\nyears <- function(temp) {(temp*0+1)*time(temp)}\n\nfyos<- function(x) {\n\t\tL <- !is.na(x)\n        idx <- c(NA, which(L))[cumsum(L) + 1]\n\t\tfy <- min(idx,na.rm=TRUE)\n\t\treturn(fy)\n\t\t}\n\ncombined <- function(y) {(years(y)-fyos(y)+1)}\nrel.years <- apply(treeringdata,2,combined)\nrel.years <- scale(rel.years,center=-pith.offset,scale=FALSE)\n\t\nif(is.ts(treeringdata)) (rel.years <- ts(rel.years, start=start(treeringdata)))\n\t\nreturn(rel.years)\n}\n\n##########################################################################################\n#function tssubset\n#\n#\n#     #example1\n#ts.plot(tssubset(testing,cambial.age(testing)>49&cambial.age(testing)<60),type=\"p\",col=1)\n#\n#     #example2\n#ca <- cambial.age(testing)\n#tssubset(testing,ca>30&ca<50)\n#\n#\n#\n##########################################################################################\ntssubset <- function(x,yandconditon){\ntemp <- eval(yandconditon)\ntemp[temp==FALSE]<- NA\nx.subset <- x*temp\ncolnames(x.subset) <- colnames(x)\nreturn(x.subset)\n}\n\n\n\n\n\n\n\n\n\n\n\n##########################################################################################\n#function ts.cor\n##########################################################################################\nts.cor <-function(x,y) {\n\ntemp <- ts.union(x,y)\ntemp.cor <- cor(temp,use=\"pairwise.complete.obs\")\ntemp.cor <- temp.cor[1:ncol(x),(ncol(x)+1):ncol(temp)]\nrownames(temp.cor) <- colnames(x)\ncolnames(temp.cor) <- colnames(y)\nreturn(temp.cor)\n}\n\n##########################################################################################\n#function EVD\n##########################################################################################\nEVD <- function(x,window=50) {\naa.x <- agealign2(x,1)\naa.x <- tspadding(aa.x,window)\naa.presence <- runningpresence(aa.x,window)\naa.x.runningsd <- rapply(aa.x,window,sd,by=1,na.pad=TRUE,na.rm=TRUE)\naa.x.runningsd[aa.presence<window/2]<-NA\naa.x.runningsd.mean <- makechronology(aa.x.runningsd)\n\nEVD.x.detrended.aa <- aa.x/aa.x.runningsd.mean\n\nEVD.x.detrended.final <- agealign2(EVD.x.detrended.aa,fy(x))\n\nEVD.x.detrended.final.crnl <- makechronology(EVD.x.detrended.final)\nts.plot(EVD.x.detrended.final.crnl)\nreturn(EVD.x.detrended.final.crnl)\n}\n\n\n##########################################################################################\n#function RCS\n##########################################################################################\n\nRCS <- function(dataset, smoothspl=40) {\n\naa <- agealign2(dataset,1)\naa.crn <- makechronology(aa)\naa.crn.smth <- splinesmoother2(aa.crn,smoothspl)\nfinished <- apply(aa,2,function(x){(x/aa.crn.smth)})\nfinished <- ts(finished)\ncal.detrended <- agealign2(finished,fy(dataset))\nrcs.crnl<- makechronology(cal.detrended)\n\nreturn(aa,aa.crn,aa.crn.smth,finished,cal.detrended,rcs.crnl)\n}\n\n\n##########################################################################################\n#function spline.det\n##########################################################################################\nspline.det <- function(x,smoothing) {\n\nspline.p.for.smooth.Pspline<-function(year)  {\n\tp <- .5/((6*(cos(2*pi/year)-1)^2/(cos(2*pi/year)+2)))\n\treturn(p)\n\t}\n\n\nifelse ((is.null(ncol(x))),x2 <- ts.union(x,x), x2 <- x)\n\nfyarray <- start(x2)[1]\nlyarray <- end(x2)[1]\nbegin <- fy(x2)\nend <- ly(x2)\n\nsmoothedarray <- x2\n\nspline.p <- spline.p.for.smooth.Pspline(smoothing)\n\n\nfor (i in 1:ncol(x2)) {\ntemp <- smooth.Pspline((begin[i]:end[i]),x2[(begin[i]-fyarray+1):(end[i]-fyarray+1),i],spar=spline.p,method=1)\nsmoothedarray[(begin[i]-fyarray+1):(end[i]-fyarray+1),i]  <- temp$ysmth\n}\n\nif (is.null(ncol(x))) {smoothedarray <- smoothedarray[,-1]}\n\nresidualarray <- x-smoothedarray\nratioarray <- x/smoothedarray\n\nreturn(x,smoothedarray,residualarray,ratioarray)\n}\n\n\n\n##########################################################################################\n#function continuous2month\n##########################################################################################\n\n\ncontinuous2month <- function(continuousmonthlymetdata) {\n\nfor (i in 1:12) \nassign(paste(\"temp\",i,sep=\"\"),ts(continuousmonthlymetdata[cycle(continuousmonthlymetdata)==i],start=start(continuousmonthlymetdata)[1]))\nmonthmatrix <- ts.union(temp1,temp2,temp3,temp4,temp5,temp6,temp7,temp8,temp9,temp10,temp11,temp12)\ncolnames(monthmatrix)<-c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\")\nreturn(monthmatrix)\n}\n\n\n\n##########################################################################################\n#function normalizevariancewindow\n##########################################################################################\nnormalizevariancewindow <- function(x, start, end) {\n\ncentered1 <- scale(x,center=apply(window(x,start,end),2,mean,na.rm=TRUE),scale=FALSE)\ncentered.means <- unlist(attributes(centered1)[\"scaled:center\"])\nscaled1 <- scale(centered1,center=FALSE,scale=apply(window(centered1,start,end),2,sd,na.rm=TRUE))\nscaled2 <- scale(scaled1,center=-centered.means,scale=FALSE)\nreturn(scaled2)\n}\n##########################################################################################\n\n\n\n\n\n\n##########################################################################################\n#function stabilizevariance4nhweightedrecon\n#\n#used in attempt to add a weighted mean for the variance stabilized nh chronols\n#does not give anything for biweight means back\n##########################################################################################\nstabilizevariance4nhweightedrecon <- function(x,WL) {\n\n\n\trunningrforSTABILIZEVARIANCE <-function (data, win.length=WL) {\n\n\t\tcor.mat <- cor(data, use=\"pairwise.complete.obs\")\n\t\tdiag(cor.mat) <- NA\n\t\tobs.overlap.mat <- observationoverlap(data)\n\t\tcor.mat[obs.overlap.mat < (win.length/3)] <- NA\n\t\tMEAN.R.trunc <- mean(cor.mat, na.rm=TRUE)\n\n\treturn(MEAN.R.trunc)\n\t}\n\nmean.x <- mean(makechronology(x),na.rm=TRUE)  #pre-process the data to have a mean of zero\nx <- x-mean.x  \n\nx.presence <- (x*0+1)\nlat2rounded <- c(60,40,60,60,40,60,60,40,60,60,40,60,60,60)\ncosweights <- cos((1/180*pi)*lat2rounded)\ncosweights<-round(cosweights,2)\n\nweightseries <- scale(x.presence,center=FALSE,scale=c(1/cosweights))\n\nrowSums(weightseries,na.rm=TRUE) -> sumofweights\nsumofweights[sumofweights==0]<-NA\n\nrowSums(x*weightseries,na.rm=TRUE) -> weightedsitesum\n\nweightedsitesum/sumofweights->latitudeweightedaveragechronol\nts(latitudeweightedaveragechronol,start=start(x))->tslatitudeweightedaveragechronol\nchronology <- tslatitudeweightedaveragechronol\n\n\n\n\nsamplesize <- tssampledepth(x)\n\n\n\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nMEAN.R <- mean(correlmatrix, na.rm =TRUE)\n\n\n\n\nrbar.running <- rapply(x,WL,runningrforSTABILIZEVARIANCE,by=1,by.column=FALSE,na.pad=TRUE)\nrbar.running <- na.locf(rbar.running,na.rm=FALSE)\nrbar.running <- rev(na.locf(rev(rbar.running),na.rm=FALSE))\nrbar.running[samplesize==0] <- NA\n\neffsamplesize <- samplesize/(1+(samplesize-1)*rbar.running)\n\neffsamplesize <- pmin(effsamplesize,samplesize,na.rm=TRUE) \n# takes care of setting the effsamplesize to 1 when sampledepth=1\n# and also if rbar goes negative effsamplesize gets larger than samplesize, and this brings it back down.\n\nsimpleeffsamplesize <- samplesize/(1+(samplesize-1)*MEAN.R)\n\n\nRUNNINGadjustedchronology <- chronology*(effsamplesize*MEAN.R)^.5\n\n\nSIMPLEadjustedchronology <- chronology*(simpleeffsamplesize*MEAN.R)^.5\n\neverything <- ts.union(chronology,SIMPLEadjustedchronology,RUNNINGadjustedchronology,samplesize,effsamplesize,rbar.running)\neverything <- scale(everything,center=c(rep(-mean.x,3),rep(0,3)),scale=FALSE)#add back the mean to the dataset\n\n\nreturn(everything)\n\n}\n##########################################################################################\n##########################################################################################\n##########################################################################################\n\n\n##########################################################################################\n#function newsplineforgaps\n#\n#as for splinesmoother, but deals with gaps\n##########################################################################################\n\n\nnewsplineforgaps <- function(x,smoothing) {\n\nspline.p.for.smooth.Pspline<-function(year)  {\n\tp <- .5/((6*(cos(2*pi/year)-1)^2/(cos(2*pi/year)+2)))\n\treturn(p)\n\t}\n\nsmoothedarray <- x\n\nspline.p <- spline.p.for.smooth.Pspline(smoothing)\n\nfor (i in 1:ncol(x)) {\ntemp.data <- x[,i]\nyear.test <- !is.na(temp.data)\nvalid.years <-index(temp.data)[year.test]\ntemp <- smooth.Pspline(valid.years,temp.data[year.test],spar=spline.p,method=1)\nsmoothedarray[year.test,i]  <- temp$ysmth\n}\nreturn(smoothedarray)\n}\n\n\n\n\n##########################################################################################\n#function splinesmoother\n#As for tree-ring type splines\n#Spar is caluclated for smooth.Pspline as .5/(formula in Cook and Peters 1981),derived by\n#trial and error. Tested for ranges of at least between 20 and 200. requires package(\"pspline\")\n#tested on version 1.0-8\n##########################################################################################\n\n\n\nsplinesmoother <- function(x,smoothing) {\n\nspline.p.for.smooth.Pspline<-function(year)  {\n\tp <- .5/((6*(cos(2*pi/year)-1)^2/(cos(2*pi/year)+2)))\n\treturn(p)\n\t}\n\nfyarray <- start(x)[1]\nlyarray <- end(x)[1]\nbegin <- fy(x)\nend <- ly(x)\n\nsmoothedarray <- x\n\nspline.p <- spline.p.for.smooth.Pspline(smoothing)\n\n\nfor (i in 1:ncol(x)) {\ntemp <- smooth.Pspline((begin[i]:end[i]),x[(begin[i]-fyarray+1):(end[i]-fyarray+1),i],spar=spline.p,method=1)\nsmoothedarray[(begin[i]-fyarray+1):(end[i]-fyarray+1),i]  <- temp$ysmth\n}\nreturn(smoothedarray)\n}\n\n\n##########################################################################################\n#function splinesmoother2\n#\n#as for splinesmoother, but deals with singlecolumns\n##########################################################################################\n\n\n\n\nsplinesmoother2 <- function(x,smoothing) {\n\nspline.p.for.smooth.Pspline<-function(year)  {\n\tp <- .5/((6*(cos(2*pi/year)-1)^2/(cos(2*pi/year)+2)))\n\treturn(p)\n\t}\n\n\nifelse ((is.null(ncol(x))),x2 <- ts.union(x,x), x2 <- x)\n\nfyarray <- start(x2)[1]\nlyarray <- end(x2)[1]\nbegin <- fy(x2)\nend <- ly(x2)\n\nsmoothedarray <- x2\n\nspline.p <- spline.p.for.smooth.Pspline(smoothing)\n\n\nfor (i in 1:ncol(x2)) {\ntemp <- smooth.Pspline((begin[i]:end[i]),x2[(begin[i]-fyarray+1):(end[i]-fyarray+1),i],spar=spline.p,method=1)\nsmoothedarray[(begin[i]-fyarray+1):(end[i]-fyarray+1),i]  <- temp$ysmth\n}\n\nif (is.null(ncol(x))) {smoothedarray <- smoothedarray[,-1]}\nreturn(smoothedarray)\n}\n\n\n\n\n\n##########################################################################################\n#function Mean.R\n#\n#\n##########################################################################################\nMean.R <- function(x,N=30) {\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nwindowoverlap <- observationoverlap(x)\ncorrelmatrix[windowoverlap<N]<-NA\nMEAN.R.result <- mean(correlmatrix, na.rm =TRUE)\nreturn(MEAN.R.result)\n}\n\n\n\n##########################################################################################\n#function runningpresence\n#\n#\n##########################################################################################\n\nrunningpresence <- function(x,windowlength) {\nrollapply(x*0+1,windowlength,sum,na.pad=TRUE,na.rm=TRUE)\n}\n\n\n\n##########################################################################################\n#function tspadding\n#\n#\n##########################################################################################\ntspadding <- function(x,n.years) {\nx.beg<- tsp(x)[1]\nx.end <- tsp(x)[2]\n\n\ttemp <- ts(rep(NA,x.end-x.beg+n.years*2+1),start=(x.beg-n.years))\n\ttemp <- ts.union(temp,x)\n\ttemp<-temp[,-1]\n\tif (is.integer(ncol(x))) colnames(temp)<- colnames(x)\nreturn(temp)\n}\n\n\n\n\n\n##########################################################################################\n#function meanandvarianceadjust\n#\n#should be ok, but doublecheck.\n##########################################################################################\n\n\nmeanandvarianceadjust <- function(originaldataset, targetdataset, startwindow,endwindow) {\n\ntarget_sd <- sd(window(targetdataset,startwindow,endwindow))\ntarget_mean <- mean(window(targetdataset,startwindow,endwindow))\nmerged <- ts.union(targetdataset,originaldataset)\nscale.data <- apply(window(merged,startwindow,endwindow),2,sd)/target_sd\n\ntemp <- scale(merged,scale=scale.data,center=FALSE)\ntemp <- ts(temp,start=start(merged)[1])\n\ncenter.data <- apply(window(temp,startwindow,endwindow),2,mean)-target_mean\n\ntemp2 <- scale(temp,scale=FALSE,center=center.data)\ntemp2 <- ts(temp2,start=start(temp)[1])\n\ntemp3 <- temp2[,-1]\n\nif (is.numeric(ncol(originaldataset))) (colnames(temp3)<-colnames(originaldataset))\n\nprint(scale.data)\nprint(center.data)\nreturn(temp3)\n}\n\n\n\n##########################################################################################\n#function meanandvarianceadjust2\n#\n#should be ok, but doublecheck.\n##########################################################################################\n\n\nmeanandvarianceadjust2 <- function(originaldataset, targetdataset, startwindow,endwindow) {\n\ntarget_sd <- sd(window(targetdataset,startwindow,endwindow))\ntarget_mean <- mean(window(targetdataset,startwindow,endwindow))\nmerged <- ts.union(targetdataset,originaldataset)\nscale.data <- apply(window(merged,startwindow,endwindow),2,sd)/target_sd\n\ntemp <- scale(merged,scale=scale.data,center=FALSE)\ntemp <- ts(temp,start=start(merged)[1])\n\ncenter.data <- apply(window(temp,startwindow,endwindow),2,mean)-target_mean\n\ntemp2 <- scale(temp,scale=FALSE,center=center.data)\ntemp2 <- ts(temp2,start=start(temp)[1])\n\ntemp3 <- temp2[,-1]\n\nif (is.numeric(ncol(originaldataset))) (colnames(temp3)<-colnames(originaldataset))\n\noutput <- NULL\noutput$values <- temp3\noutput$scale <- scale.data[2]\noutput$center <- center.data[2]\nreturn(output)\n}\n\n\n##########################################################################################\n#function agealign2\n#\n#slow,but works\n##########################################################################################\n\nagealign2 <- function(x,age.vector) {\n\nif (length(age.vector)==1) age.vector <- rep(age.vector,ncol(x))\nstopifnot (length(age.vector)== ncol(x))\n\n\nfy.vector <- fy(x)\nly.vector <- ly(x)\n\nresult <- ts(window(x[,1],start=fy.vector[1],end=ly.vector[1]),start=age.vector[1])\n\nfor (i in 2:ncol(x)) {\n\ttemp1 <- ts(window(x[,i],start=fy.vector[i],end=ly.vector[i]),start=age.vector[i])\n\tresult <- ts.union(result,temp1)\n\t}\ncolnames(result) <- colnames(x)\n\nreturn(result)\n}\n\n\n##########################################################################################\n#function agealign  \n#\n#slow,but works\n##########################################################################################\n\n\nagealign <- function(x) {\n\nfy.vector <- fy(x)\nly.vector <- ly(x)\n\nresult <- ts(window(x[,1],start=fy.vector[1],end=ly.vector[1]),start=1)\n\nfor (i in 2:ncol(x)) {\n\ttemp1 <- ts(window(x[,i],start=fy.vector[i],end=ly.vector[i]),start=1)\n\tresult <- ts.union(result,temp1)\n\t}\ncolnames(result) <- colnames(x)\n\nreturn(result)\n}\n\n\n#image(d,col=rev(rainbow(50,start=0,end=4/6,gamma=1))) \n##########################################################################################\n#function beamplot\n##########################################################################################\n\nbeamplot <- function(x, ...) {\n\nx.presence <- (x*0+1)\nxseries <- scale(x.presence,center=FALSE,scale=c(1/(1:ncol(x))))\nts.plot(xseries, ...)\n}\n##########################################################################################\n\n##########################################################################################\n#function newbiweightrobustmean\n#\n#if using on a data.frame call function as: biweightrobustmean(as.matrix(x))\n#this seems to be slower than the older version ....shit ;-)\n##########################################################################################\n\nnewbiweightrobustmean <- function(x) {\n\n\ttempmean <- rep(NA,nrow(x))\n\tsampledepth<-rowSums(0*x+1, na.rm=TRUE)\n\trawmedian<- apply(x,1,median,na.rm=TRUE)\n\tx_norm <- (x-rawmedian)/apply(x,1,mad,na.rm=TRUE) # here using median absolute deviation and initial estimate with median instead, maybe more robust\n\n\tfor (i in 1:3) {\n\t\tx_norm[abs(x_norm) > 6.08] <- 6.08      # special consideration for any extreme value over 6.08 stdev away to get weight of 6.08 stdev which is zero\n\t\txweights <- ((1-(x_norm/6.08)^2)^2)\n\t\t\n\t\tweightsums <-rowSums(xweights,na.rm=TRUE)\n\t\tweightsums[weightsums==0]<-NA\n\t\ttempmean <- rowSums(x*xweights,na.rm=TRUE)/weightsums\n\t\t\t\n\t\t\n\t\tx_norm <- (x-tempmean)/apply(x,1,mad, na.rm=TRUE) # here using median absolute deviation\n\t}\n\n\ttempmean[which(sampledepth==1)]<-rawmedian[which(sampledepth==1)]\n\n\tifelse(is.ts(x)==TRUE, robustmean <- ts(tempmean, start = start(x)[1]), robustmean <- tempmean)\nrobustmean\n}\n\n###############\nfy <- function(object) {\n\nfyos<- function(x) {\n\t\tL <- !is.na(x)\n        idx <- c(NA, which(L))[cumsum(L) + 1]\n\t\tfy <- min(idx,na.rm=TRUE)\n\t\treturn(fy)\n\t\t}\n\nifelse (is.mts(object), \n\trel.years <- apply(object,2,fyos),\n\trel.years <- fyos(object))\n\t\ncalyears <- rel.years+start(object)[1]-1\nreturn(calyears)\n}\n\n###############\n\n###############\nly <- function(object) {\n\nfyos<- function(x) {\n\t\tL <- !is.na(x)\n        idx <- c(NA, which(L))[cumsum(L) + 1]\n\t\tfy <- max(idx,na.rm=TRUE)\n}\n\nifelse (is.mts(object), \n\trel.years <- apply(object,2,fyos),\n\trel.years <- fyos(object))\n\t\ncalyears <- rel.years+start(object)[1]-1\nreturn(calyears)\n}\n###############\n\n\n\n\n\n#########################################################################################################\n#wooooo function sorted beam plot\n#########################################################################################################\nsortedbeamplot <- function(x,direction=c(\"none\",\"ascending\",\"descending\"),datareturn=FALSE, ...) {\n\n\ndirection <- match.arg(direction)\n\n\n\tcolumnsorter <- function(object, columnindexer) {\n\t\tif (ncol(object)!=length(columnindexer)) stop(\"length of column vector does not equal number of columns\")\n\t\tnew.ind <- sort(columnindexer,index.return=TRUE)\n\t\tx <- x[,c(new.ind$ix)]\n\t}\n\n\nif (direction==\"ascending\") {\nx.ly <- ly(x)\nx <-  columnsorter(x,x.ly)\nx.fy <- fy(x)\nx <-  columnsorter(x,x.fy)\n}\n\nif (direction==\"descending\") {\nx.fy <- fy(x)\nx <-  columnsorter(x,x.fy)\nx.ly <- ly(x)\nx <-  columnsorter(x,x.ly)\n}\n\n\nif (direction==\"none\") {\nbeamplot(x, ...)\n}\n\nelse {beamplot(x, ...)}\n\nif (datareturn) return(x)\n\n}\n###################################################################################################################################################################################################\n#function writemeasformat !!!!!!\n##########################################################################################\n\nwritemeasformat <- function(x) {\n\nseriesnames <- strtrim(dimnames(x)[[2]],8)\n\nfor (j in 1:ncol(x)) {\n\n\ttemp.x <- na.contiguous(x[,j])\n\tbegining.year <- start(temp.x)[1]\n\tyear <- begining.year\n\n\tfor (i in 1:length(temp.x)) {\n\t\tif (i==1) cat(encodeString(seriesnames[j],w=8,justify=\"left\"),encodeString(year,w=4,justify=\"right\"),sep=\"\")\n\t\tif(year%%10!=9) cat(noquote(encodeString(temp.x[i],w=6,justify=\"right\")))\n\t\tif (year%%10==9) {\n\t\t\tcat(noquote(encodeString(temp.x[i],w=6,justify=\"right\")))\n\t\t\tcat(\"\\n\",encodeString(seriesnames[j],w=8,justify=\"left\"),encodeString(year+1,w=4,justify=\"right\"),sep=\"\")\n\t\t\t}\n\t\tif (i==length(temp.x)) cat(\"\",\"-9999\",\"\\n\")\n\t\tyear=year+1\n}\n\n}\n\n}\n\n\n\n##########################################################################################\n#function stabilizevariance5nhweightedrecon\n#(requires zoo) \n##########################################################################################\nstabilizevariance5nhweightedrecon <- function(x,WL) {\n\n\n\trunningrforSTABILIZEVARIANCE <-function (data, win.length=WL) {\n\n\t\tcor.mat <- cor(data, use=\"pairwise.complete.obs\")\n\t\tdiag(cor.mat) <- NA\n\t\tobs.overlap.mat <- observationoverlap(data)\n\t\tcor.mat[obs.overlap.mat < (win.length/3)] <- NA\n\t\tMEAN.R.trunc <- mean(cor.mat, na.rm=TRUE)\n\n\treturn(MEAN.R.trunc)\n\t}\n\nmean.x <- mean(makechronology(x),na.rm=TRUE)  #pre-process the data to have a mean of zero\nx <- x-mean.x  \n\nx.presence <- (x*0+1)\nlat2rounded <- c(60,50,60,60,50,60,60,50,60,60,50,60,60,60)\ncosweights <- cos((1/180*pi)*lat2rounded)\ncosweights<-round(cosweights,2)\n\nweightseries <- scale(x.presence,center=FALSE,scale=c(1/cosweights))\n\nrowSums(weightseries,na.rm=TRUE) -> sumofweights\nsumofweights[sumofweights==0]<-NA\n\nrowSums(x*weightseries,na.rm=TRUE) -> weightedsitesum\n\nweightedsitesum/sumofweights->latitudeweightedaveragechronol\nts(latitudeweightedaveragechronol,start=start(x))->tslatitudeweightedaveragechronol\nchronology <- tslatitudeweightedaveragechronol\n\n\n\n\nsamplesize <- tssampledepth(x)\n\n\n\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nMEAN.R <- mean(correlmatrix, na.rm =TRUE)\n\n\n\n\nrbar.running <- rollapply(x,WL,runningrforSTABILIZEVARIANCE,by=1,by.column=FALSE,na.pad=TRUE)\nrbar.running <- na.locf(rbar.running,na.rm=FALSE)\nrbar.running <- rev(na.locf(rev(rbar.running),na.rm=FALSE))\nrbar.running[samplesize==0] <- NA\n\neffsamplesize <- samplesize/(1+(samplesize-1)*rbar.running)\n\neffsamplesize <- pmin(effsamplesize,samplesize,na.rm=TRUE) \n# takes care of setting the effsamplesize to 1 when sampledepth=1\n# and also if rbar goes negative effsamplesize gets larger than samplesize, and this brings it back down.\n\nsimpleeffsamplesize <- samplesize/(1+(samplesize-1)*MEAN.R)\n\n\nRUNNINGadjustedchronology <- chronology*(effsamplesize*MEAN.R)^.5\n\n\nSIMPLEadjustedchronology <- chronology*(simpleeffsamplesize*MEAN.R)^.5\n\neverything <- ts.union(chronology,SIMPLEadjustedchronology,RUNNINGadjustedchronology,samplesize,effsamplesize,rbar.running)\neverything <- scale(everything,center=c(rep(-mean.x,3),rep(0,3)),scale=FALSE)#add back the mean to the dataset\n\n\nreturn(everything)\n\n}\n\n\n##########################################################################################\n#function stabilizevariance3\n#(requires zoo) includes automatic removal of dataset mean in comparison to stablizevariance2\n##########################################################################################\nstabilizevariance3 <- function(x,WL) {\n\n\n\trunningrforSTABILIZEVARIANCE <-function (data, win.length=WL) {\n\n\t\tcor.mat <- cor(data, use=\"pairwise.complete.obs\")\n\t\tdiag(cor.mat) <- NA\n\t\tobs.overlap.mat <- observationoverlap(data)\n\t\tcor.mat[obs.overlap.mat < (win.length/3)] <- NA\n\t\tMEAN.R.trunc <- mean(cor.mat, na.rm=TRUE)\n\n\treturn(MEAN.R.trunc)\n\t}\n\nmean.x <- mean(makechronology(x),na.rm=TRUE)  #pre-process the data to have a mean of zero\nx <- x-mean.x  \n\n\nsamplesize <- tssampledepth(x)\nchronology <- makechronology(x)\nbiwgt.chronology <- biweightrobustmean(x)\n\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nMEAN.R <- mean(correlmatrix, na.rm =TRUE)\n\n\n\n\nrbar.running <- rollapply(x,WL,runningrforSTABILIZEVARIANCE,by=1,by.column=FALSE,na.pad=TRUE)\nrbar.running <- na.locf(rbar.running,na.rm=FALSE)\nrbar.running <- rev(na.locf(rev(rbar.running),na.rm=FALSE))\nrbar.running[samplesize==0] <- NA\n\neffsamplesize <- samplesize/(1+(samplesize-1)*rbar.running)\n\neffsamplesize <- pmin(effsamplesize,samplesize,na.rm=TRUE) \n# takes care of setting the effsamplesize to 1 when sampledepth=1\n# and also if rbar goes negative effsamplesize gets larger than samplesize, and this brings it back down.\n\nsimpleeffsamplesize <- samplesize/(1+(samplesize-1)*MEAN.R)\n\n\nRUNNINGadjustedchronology <- chronology*(effsamplesize*MEAN.R)^.5\nRUNNINGadjusted.biwgt.chronology  <- biwgt.chronology*(effsamplesize*MEAN.R)^.5\n\n\nSIMPLEadjustedchronology <- chronology*(simpleeffsamplesize*MEAN.R)^.5\nSIMPLEadjusted.biwgt.chronology <- biwgt.chronology*(simpleeffsamplesize*MEAN.R)^.5\n\n\neverything <- ts.union(chronology,biwgt.chronology,SIMPLEadjustedchronology,SIMPLEadjusted.biwgt.chronology,RUNNINGadjustedchronology,RUNNINGadjusted.biwgt.chronology,samplesize,effsamplesize,rbar.running)\neverything <- scale(everything,center=c(rep(-mean.x,6),rep(0,3)),scale=FALSE)#add back the mean to the dataset\n\n\nreturn(everything)\n\n}\n\n\n\n##########################################################################################\n#function stabilizevariance2\n#(requires zoo)\n##########################################################################################\nstabilizevariance2 <- function(x,WL) {\n\n\n\trunningrforSTABILIZEVARIANCE <-function (data, win.length=WL) {\n\n\t\tcor.mat <- cor(data, use=\"pairwise.complete.obs\")\n\t\tdiag(cor.mat) <- NA\n\t\tobs.overlap.mat <- observationoverlap(data)\n\t\tcor.mat[obs.overlap.mat < (win.length/3)] <- NA\n\t\tMEAN.R <- mean(cor.mat, na.rm=TRUE)\n\n\treturn(MEAN.R)\n\t}\n\n\n\n\nsamplesize <- tssampledepth(x)\nchronology <- makechronology(x)\nbiwgt.chronology <- biweightrobustmean(x)\n\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nMEAN.R <- mean(correlmatrix, na.rm =TRUE)\n\n\n\n\nrbar.running <- rapply(x,WL,runningrforSTABILIZEVARIANCE,by=1,by.column=FALSE,na.pad=TRUE)\nrbar.running <- na.locf(rbar.running,na.rm=FALSE)\nrbar.running <- rev(na.locf(rev(rbar.running),na.rm=FALSE))\nrbar.running[samplesize==0] <- NA\n\neffsamplesize <- samplesize/(1+(samplesize-1)*rbar.running)\n\neffsamplesize <- pmin(effsamplesize,samplesize,na.rm=TRUE) \n# takes care of setting the effsamplesize to 1 when sampledepth=1\n# and also if rbar goes negative effsamplesize gets larger than samplesize, and this brings it back down.\n\nsimpleeffsamplesize <- samplesize/(1+(samplesize-1)*MEAN.R)\n\n\nRUNNINGadjustedchronology <- chronology*(effsamplesize*MEAN.R)^.5\nRUNNINGadjusted.biwgt.chronology  <- biwgt.chronology*(effsamplesize*MEAN.R)^.5\n\n\nSIMPLEadjustedchronology <- chronology*(simpleeffsamplesize*MEAN.R)^.5\nSIMPLEadjusted.biwgt.chronology <- biwgt.chronology*(simpleeffsamplesize*MEAN.R)^.5\n\n\neverything <- ts.union(chronology,biwgt.chronology,SIMPLEadjustedchronology,SIMPLEadjusted.biwgt.chronology,RUNNINGadjustedchronology,RUNNINGadjusted.biwgt.chronology,samplesize,effsamplesize,rbar.running)\n\nreturn(everything)\n\n}\n\n\n\n##########################################################################################\n#function stabilizevariance\n##########################################################################################\nstabilizevariance <-function(x,WL) {\n\nsamplesize <- tssampledepth(x)\nchronology <- makechronology(x)\n\ncorrelmatrix <- cor(x,use=\"pairwise.complete.obs\") # could insert code for using only correls with certain observation overlap\ndiag(correlmatrix) <- NA\nMEAN.R <- mean(correlmatrix, na.rm =TRUE)\n\nrbar.running <- rapply(x,WL,runningrforRAPPLY,by=1,by.column=FALSE,na.pad=TRUE, WINDOW=WL)\n\neffsamplesize <- samplesize/(1+(samplesize-1)*rbar.running)\n\neffsamplesize <- pmin(effsamplesize,samplesize,na.rm=TRUE) \n# takes care of setting the effsamplesize to 1 when sampledepth=1\n# and also if rbar goes negative effsamplesize gets larger than samplesize, and this brings it back down.\n\nRUNNINGadjustedchronology <- chronology*(effsamplesize*MEAN.R)^.5\n\nsimpleeffsamplesize <- samplesize/(1+(samplesize-1)*MEAN.R)\nSIMPLEadjustedchronology <- chronology*(simpleeffsamplesize*MEAN.R)^.5\n\n\neverything <- ts.union(chronology,RUNNINGadjustedchronology,SIMPLEadjustedchronology,effsamplesize,samplesize,rbar.running)\n\nreturn(everything)\n\n}\n\n\n##########################################################################################\n#function runningrforRAPPLY\n#\n# efficient !\n##########################################################################################\n\n\nrunningrforRAPPLY <-function (x, WL=50) {\n\ncor.mat <- cor(x, use=\"pairwise.complete.obs\")\ndiag(cor.mat) <- NA\nobs.overlap.mat <- observationoverlap(x)\ncor.mat[obs.overlap.mat < (WL/3)] <- NA\nMEAN.R <- mean(cor.mat, na.rm=TRUE)\n\nreturn(MEAN.R)\n\n}\n\n\n##########################################################################################\n#\n#function runningcorrel\n#\n#calls functions observationoverlap\n#\n#correlations run from last year of chronology to first year\n#time series run this way also!\n#\n##########################################################################################\nrunningcorrel <- function(x,windowlength,stepsize) {\n\nNcorrelpairs <- ceiling((tsp(x)[2]-tsp(x)[1]-windowlength)/stepsize)+1\nwindowcorrels <- array(NA, dim=c(ncol(x),ncol(x),Ncorrelpairs))\nwindowoverlap <- array(NA, dim=c(ncol(x),ncol(x),Ncorrelpairs))\nwindowend <- tsp(x)[2]\nwindowbegin <- windowend-windowlength+1\ni <- 1\ncentralyears <- NA\nrbar_simple <- NA\nmeansampledepth <- NA\n\n\twhile (windowbegin > tsp(x)[1]) {\n\t\ttempwindow <- window(x,start=windowbegin,end=windowend,extend = FALSE)\n\t\twindowoverlap[,,i] <- observationoverlap(tempwindow)\n\t\ttempwindowcorrels  <- cor(tempwindow,use=\"pairwise.complete.obs\")\n\t\tdiag(tempwindowcorrels) <- NA\n\t\ttempwindowcorrels[windowoverlap[,,i]< windowlength/2] <- NA\n\t\trbar_simple[i] <- mean(tempwindowcorrels, na.rm= TRUE)\n\t\twindowcorrels[,,i] <- tempwindowcorrels\n\t\t#diag(windowcorrels[,,i] <- NA\n\t\tcentralyears[i] <- ceiling(windowbegin+windowend)/2\n\t\tmeansampledepth[i] <- mean(rowSums((tempwindow*0+1),na.rm=TRUE))\n\n\t\twindowend<-windowend-stepsize\n\t\twindowbegin<- windowend-windowlength+1\n\t\ti<-i+1\n\n\t}\t\n\nreturn(windowcorrels, windowoverlap,centralyears,rbar_simple,meansampledepth)\n\n}\n\n\n\n\n##########################################################################################\n#\n#function fastrunningcorrelforvarianceadjustment\n#\n# same as slow version, but does not store all of the intermediate data matrix stuff.\n#\n#\n#calls functions observationoverlap\n#\n#correlations run from first year of chronology to last year\n#time series run this way also!\n#\n##########################################################################################\n\n\nfastrunningcorrelforvarianceadjustment <- function(x,windowlength,stepsize) {\n\nNcorrelpairs <- ceiling(tsp(x)[2]-tsp(x)[1])+1\ntempwindowcorrels <- matrix(NA,ncol(x),ncol(x))\ntempwindowoverlap <- matrix(NA,ncol(x),ncol(x))\nwindowbegin <- tsp(x)[1]-windowlength/2\nwindowend <- windowbegin+windowlength-1\ni <- 1\ncentralyears <- NA\nrbar_simple <- NA\nmeansampledepth <- NA\n\n\n\twhile (windowend-windowlength/2 < tsp(x)[2]) {\n\t\ttempwindow <- window(x,start=windowbegin,end=windowend,extend = FALSE)\n\t\ttempwindowoverlap <- observationoverlap(tempwindow)\n\t\ttempwindowcorrels  <- cor(tempwindow,use=\"pairwise.complete.obs\")\n\t\tdiag(tempwindowcorrels) <- NA\n\t\ttempwindowcorrels[tempwindowoverlap < windowlength/2] <- NA  # condition to get rid of correls with not enough overlap, now half window width\n\t\trbar_simple[i] <- mean(tempwindowcorrels, na.rm= TRUE)\n\t\tcentralyears[i] <- ceiling((windowbegin+windowend)/2)\n\t\tmeansampledepth[i] <- mean(rowSums((tempwindow*0+1),na.rm=TRUE))\n\t\twindowbegin <- windowbegin + stepsize\n\t\twindowend <- windowbegin + windowlength-1\n\t\ti<-i+1\n\n\t}\n\nreturn(centralyears,rbar_simple,meansampledepth)\n\n}\n\n\n\n\n##########################################################################################\n#\n#function runningcorrelforvarianceadjustment\n#\n#calls functions observationoverlap\n#\n#correlations run from last year of chronology to first year\n#time series run this way also!\n#\n##########################################################################################\nrunningcorrelforvarianceadjustment <- function(x,windowlength,stepsize) {\n\nNcorrelpairs <- ceiling(tsp(x)[2]-tsp(x)[1])+1\nwindowcorrels <- array(NA, dim=c(ncol(x),ncol(x),Ncorrelpairs))\nwindowoverlap <- array(NA, dim=c(ncol(x),ncol(x),Ncorrelpairs))\nwindowbegin <- tsp(x)[1]-windowlength/2\nwindowend <- windowbegin+windowlength-1\ni <- 1\ncentralyears <- NA\nrbar_simple <- NA\nmeansampledepth <- NA\n\n\twhile (windowend-windowlength/2 < tsp(x)[2]) {\n\t\ttempwindow <- window(x,start=windowbegin,end=windowend,extend = FALSE)\n\t\twindowoverlap[,,i] <- observationoverlap(tempwindow)\n\t\ttempwindowcorrels  <- cor(tempwindow,use=\"pairwise.complete.obs\")\n\t\tdiag(tempwindowcorrels) <- NA\n\t\ttempwindowcorrels[windowoverlap[,,i]< windowlength/2] <- NA  # condition to get rid of correls with not enough overlap\n\t\trbar_simple[i] <- mean(tempwindowcorrels, na.rm= TRUE)\n\t\twindowcorrels[,,i] <- tempwindowcorrels\n\t\t#diag(windowcorrels[,,i] <- NA\n\t\tcentralyears[i] <- ceiling(windowbegin+windowend)/2\n\t\tmeansampledepth[i] <- mean(rowSums((tempwindow*0+1),na.rm=TRUE))\n\n\t\twindowbegin <- windowbegin + stepsize\n\t\twindowend <- windowbegin + windowlength-1\n\t\ti<-i+1\n\n\t}\t\n\nreturn(windowcorrels, windowoverlap,centralyears,rbar_simple,meansampledepth)\n\n}\n\n\n\n##########################################################################################\n#function EPS\n##########################################################################################\n\nEPS <- function(N=samplesize,r=rbar) {\n\n(N*r)/(1+N*r-r)\n\n}\n\n\n##########################################################################################\n#function SSS  ***untested****\n##########################################################################################\n\nSSS <- function (n=maxsampledepth,N=sampledepthsubset,r=rbar) {\n\n(n*(1+(N-1)*r))/(N*(1+(n-1)*r))\n\n}\n\n\n##########################################################################################\n#function observationoverlap\n#\n# efficient !\n##########################################################################################\n\nobservationoverlap <- function(x) {\n\tpresencematrix <- 0*(as.matrix(x))+1\n\tpresencematrix[is.na(presencematrix)] <- 0\n\toverlapmatrix <- t(presencematrix)%*%presencematrix\n\toverlapmatrix\n}\n\n\n\n\n##########################################################################################\n#function observationoverlap\n#\n# damn slow !\n##########################################################################################\n#\n#observationoverlap <- function(x) {\n#\n#size <- ncol(x)\n#overlapmatrix <- matrix(NA,size,size)\n#presencematrix <- 0*(as.data.frame(x))+1\n#\n#\tfor (i in 1:size) {\n#\t\tfor (j in 1:size)\n#\t\t\toverlapmatrix[i,j]<-sum(presencematrix[,i]*presencematrix[,j],na.rm=TRUE)\n#\t}\n#overlapmatrix\n#}\n#\n\n\n\n##########################################################################################\n#function biweightrobustmean\n#\n#if using on a data.frame call function as: biweightrobustmean(as.matrix(x))\n#\n##########################################################################################\n\nbiweightrobustmean <- function(x) {\n\n\ttempmean <- rep(NA,nrow(x))\n\tsampledepth<-rowSums(0*x+1, na.rm=TRUE)\n\trawmedian<- apply(x,1,median,na.rm=TRUE)\n\tx_norm <- (x-rawmedian)/apply(x,1,mad,na.rm=TRUE) # here using median absolute deviation and initial estimate with median instead, maybe more robust\n\n\tfor (i in 1:3) {\n\t\tx_norm[abs(x_norm) > 6.08] <- 6.08      # special consideration for any extreme value over 6.08 stdev away to get weight of 6.08 stdev which is zero\n\t\txweights <- ((1-(x_norm/6.08)^2)^2)\n\t\t\n\t\t\tfor (j in 1:nrow(x)) {\n\t\t\ttempmean[j] <- weighted.mean(x[j,],xweights[j,], na.rm=TRUE)\n\t\t\t}\n\t\t\n\t\tx_norm <- (x-tempmean)/apply(x,1,mad, na.rm=TRUE) # here using median absolute deviation\n\t}\n\n\ttempmean[which(sampledepth==1)]<-rawmedian[which(sampledepth==1)]\n\n\tifelse(is.ts(x)==TRUE, robustmean <- ts(tempmean, start = start(x)[1]), robustmean <- tempmean)\nrobustmean\n}\n\n\n\n\n##########################################################################################\n#function normalizewindow\n##########################################################################################\n\nnormalizewindow <- function(x, start, end) {\nscale(x,center=colMeans(window(x,start,end)),scale=apply(window(x,start,end),2,sd))\n}\n\n\n##########################################################################################\n#function makechronology\n##########################################################################################\n\nmakechronology <- function(x) {ts(rowMeans(x,na.rm=TRUE),start=start(x)[1])}\n\n##########################################################################################\n#function importtreeringdata\n##########################################################################################\n\nimporttreeringdata <- function(x) {\n\t\n\ttempimport <- scan(file=x,sep = \"\\t\", skip=1, na.strings=\"-9.9900\")\n\ttempimportnames <- scan(file=x,sep = \"\\t\", skip=0, na.strings=\"-9.9900\",nlines=1, what=\"character\")\n\t\n\ttreeringdata <- matrix(tempimport,ncol=length(tempimportnames), byrow=TRUE)\n\tcolnames(treeringdata) <- tempimportnames\n\ttstreeringdata <- ts(treeringdata[,-1], start=treeringdata[1,1])\n\t\n\ntstreeringdata\n}\n\n##########################################################################################\n#function tssampledepth\n##########################################################################################\ntssampledepth <- function(x) {\n\t\n\ttssampledepth <- rowSums(0*x+1, na.rm=TRUE)\n\tif (is.ts(x)) { tssampledepth <- ts(tssampledepth, start=start(x), frequency=frequency(x))}\n\t\n\treturn(tssampledepth)\n}\n\n##########################################################################################\n#function addsampledepth\n##########################################################################################\naddsampledepth <-function(x) {\n\t\n\tpar(new=TRUE)\n\t\n\tif(is.ts(x) && !is.mts(x)) {sampledepth <- x }\n\tif(is.mts(x)) { sampledepth <- tssampledepth(x) }\n\tts.plot(sampledepth, gpars=list(axes=FALSE, ann=FALSE, col=\"black\", lty=1))\n\taxis(4)\n\tmtext(\" Sample Size\", side = 4, adj=0, line=-1.2)\n}\n\n\n\n\n\n\n##\n#randomstuff\n#\n#runningcorrel(xtscut,50,1)->f\n#cbind(f$centralyears,f$rbar_simple,f$meansampledepth)->fts\n#\n##\n",
    "created" : 1424208691803.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2190695337",
    "id" : "B471FF98",
    "lastKnownWriteTime" : 1347439044,
    "path" : "~/Desktop/Flurin's niwot data/scripts/allfunctionsdavid.v13.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}